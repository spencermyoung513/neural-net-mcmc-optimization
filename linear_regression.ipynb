{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with MCMC Simulated Annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BiccKiTQmuaE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from mcmc_optimization import optimize_via_mcmc\n",
    "from models import LinearLayer\n",
    "from data_samplers import BatchSampler\n",
    "from proposal_generators import LinearLayerGaussianProposalGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pure interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jIxUQtEomxuZ"
   },
   "outputs": [],
   "source": [
    "# Generate data.\n",
    "\n",
    "true_function = lambda x: 3*x+5\n",
    "len_data = 1000\n",
    "x_vals = np.linspace(-10,10,len_data)\n",
    "y_vals = true_function(x_vals)\n",
    "\n",
    "plt.title(\"Deterministic Linear Data\")\n",
    "plt.scatter(x_vals, y_vals, s=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "He9klikFWhaI"
   },
   "source": [
    "In the example below we use a Gaussian random walk for our proposal Markov Chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_params = {'w': 0.2, 'b': 6}\n",
    "data_sampler = BatchSampler(X=x_vals, y=y_vals)\n",
    "proposal_generator = LinearLayerGaussianProposalGenerator(scale=1.1)\n",
    "\n",
    "best_params, history = optimize_via_mcmc(LinearLayer, initial_params, data_sampler, proposal_generator, mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hTMUldb1oOHA",
    "outputId": "a017dd09-38c3-4300-bf98-63ff2d9839f9"
   },
   "outputs": [],
   "source": [
    "print(f\"Proportion of proposals accepted: {history['acceptance_ratio']:.4f}\")\n",
    "print(f\"Best parameters found: w={best_params['w']}, b={best_params['b']}\")\n",
    "print(f\"Best achieved loss: {min(history['loss_values']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "TaIm0kARcKJD",
    "outputId": "46e7a55a-4198-4079-8dbc-b5bd07c4f9fb"
   },
   "outputs": [],
   "source": [
    "w_vals = history['parameter_values']['w']\n",
    "b_vals = history['parameter_values']['b']\n",
    "\n",
    "plt.plot(w_vals, b_vals, '-->', label=\"Path\")\n",
    "plt.plot(best_params['w'], best_params['b'], 'o', label=\"Estimated Minimizer\")\n",
    "plt.plot([3], [5], 'o', label=\"True Minimizer\")\n",
    "plt.xlabel(\"w\")\n",
    "plt.ylabel(\"b\")\n",
    "plt.legend()\n",
    "plt.title(\"MCMC Weight Selection\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_XyQlkueJU1"
   },
   "source": [
    "## Noisy regression (univariate contrived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data.\n",
    "\n",
    "true_function = lambda x: 3*x+5\n",
    "len_data = 1000\n",
    "x_vals = np.linspace(-10,10,len_data)\n",
    "y_vals = true_function(x_vals) + np.random.normal(scale=2, size=len(x_vals))\n",
    "\n",
    "plt.title(\"Noisy Linear Data\")\n",
    "plt.scatter(x_vals, y_vals, s=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression model the standard way.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "ground_truth_linear = LinearRegression().fit(x_vals.reshape(-1, 1), y_vals)\n",
    "\n",
    "ground_truth_linear.coef_, ground_truth_linear.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression model using MCMC.\n",
    "\n",
    "initial_params = {'w': 0.2, 'b': 6}\n",
    "data_sampler = BatchSampler(X=x_vals, y=y_vals)\n",
    "proposal_generator = LinearLayerGaussianProposalGenerator(scale=1.1)\n",
    "\n",
    "best_params, history = optimize_via_mcmc(LinearLayer, initial_params, data_sampler,\n",
    "                                         proposal_generator, mean_squared_error, num_iterations=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Proportion of proposals accepted: {history['acceptance_ratio']:.4f}\")\n",
    "print(f\"Best parameters found: w={best_params['w']}, b={best_params['b']}\")\n",
    "print(f\"Best achieved loss: {min(history['loss_values']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_vals = history['parameter_values']['w']\n",
    "b_vals = history['parameter_values']['b']\n",
    "\n",
    "plt.plot(w_vals, b_vals, '-->', label=\"Path\")\n",
    "plt.plot(best_params['w'], best_params['b'], 'o', label=\"Estimated Minimizer\")\n",
    "plt.plot([3], [5], 'o', label=\"True Minimizer\")\n",
    "plt.xlabel(\"w\")\n",
    "plt.ylabel(\"b\")\n",
    "plt.legend()\n",
    "plt.title(\"MCMC Weight Selection\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot OLS regression against MCMC method.\n",
    "\n",
    "plt.scatter(x_vals, y_vals, s=5, alpha=0.3)\n",
    "plt.plot(x_vals, best_params['w'] * x_vals + best_params['b'], '--', label=\"MCMC Learned\", c='r')\n",
    "plt.plot(x_vals, ground_truth_linear.predict(x_vals.reshape(-1, 1)), '--', label=\"OLS Regression\", c='k')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-life linear regression (multivariate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_linear = LinearRegression().fit(X_train, y_train)\n",
    "actual_w, actual_b = ground_truth_linear.coef_, ground_truth_linear.intercept_\n",
    "\n",
    "print(f\"w = {np.round(actual_w, 3)}\\n b = {actual_b}\")\n",
    "print(f\"MSE = {mean_squared_error(y_train, ground_truth_linear.predict(X_train))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_params = {'w': np.random.normal(size=X_train.shape[1]), 'b': np.random.uniform(-30, 30)}\n",
    "data_sampler = BatchSampler(X=X_train, y=y_train)\n",
    "proposal_generator = LinearLayerGaussianProposalGenerator(scale=1.1, decay=(1 - 1e-7))\n",
    "\n",
    "best_params, history = optimize_via_mcmc(LinearLayer, initial_params, data_sampler,\n",
    "                                         proposal_generator, mean_squared_error, \n",
    "                                         beta=1e-4, num_iterations=25000, batch_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Proportion of proposals accepted: {history['acceptance_ratio']:.4f}\")\n",
    "print(f\"Best parameters found: w={np.round(best_params['w'], 3)}, b={np.round(best_params['b'], 3)}\")\n",
    "print(f\"Best achieved loss: {min(history['loss_values']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Computed Loss Values\")\n",
    "plt.plot(np.log(history['loss_values']))\n",
    "plt.ylabel(\"$log(MSE)$\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_vals = np.row_stack(history['parameter_values']['w'])\n",
    "b_vals = np.row_stack(history['parameter_values']['b'])\n",
    "\n",
    "w_vals.shape, b_vals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Normed Difference from Known Minimizer\")\n",
    "plt.plot((np.linalg.norm(w_vals - actual_w, axis=1) + np.abs(b_vals - actual_b).ravel()))\n",
    "plt.ylabel(\"$||\\mathbf{\\\\theta^{*}} - \\mathbf{\\hat{\\\\theta}}||$\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In linear regression, at least, we are not approaching the optimizer with this method."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
